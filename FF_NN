{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDS576Asg1Q5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfxIkuMeAp3s",
        "colab_type": "text"
      },
      "source": [
        "###Q5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P77U10QhAZil",
        "colab_type": "text"
      },
      "source": [
        "##### PART 1: Build the above classifiers using Keras and Tensorflow and solve the classification problem for MNIST/Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EfrBitS_9VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense,LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop,SGD,Adagrad\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b5p9O_H8vkL",
        "colab_type": "text"
      },
      "source": [
        "###Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lD9usTJaNGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9cfcdff3-d0b5-4cf1-ee0a-137bb07533a2"
      },
      "source": [
        "(x_train ,y_train), (x_test,y_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PIfvrSb9CRo",
        "colab_type": "text"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzMU37IvaQqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6e8156da-775f-4b36-ceb3-f61fd941980c"
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2b4180ae80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMWiRKnKdlP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "195a8876-0158-4de9-9e8e-6c9a4ac9646e"
      },
      "source": [
        "i=0\n",
        "for images,label in zip(x_train,y_train): \n",
        "  ax = plt.subplot(2, 2, i + 1) \n",
        "  plt.imshow(images) \n",
        "  plt.title(label)\n",
        "  plt.axis(\"off\")\n",
        "  i+=1\n",
        "  if i==4:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlKbgwaSeRWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "43e0375b-4b44-4261-f15f-3d0f8f9e95a2"
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2b41200278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDa5DUwh9LWx",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgnUcx2b06t4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = x_test/255.0\n",
        "x_train = x_train/255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpN1h34F9TSY",
        "colab_type": "text"
      },
      "source": [
        "### 2 Layer Feed forward NN Model with Leaky ReLU (Adam)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-VXyf5iiJAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bed41e98-85f1-4286-be59-3e62b6432e51"
      },
      "source": [
        "model_LeakyReLU = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(128,activation=LeakyReLU()), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_LeakyReLU.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_LeakyReLU.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5138 - accuracy: 0.8194\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4029 - accuracy: 0.8573\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3697 - accuracy: 0.8665\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3474 - accuracy: 0.8741\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3338 - accuracy: 0.8779\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3211 - accuracy: 0.8832\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3090 - accuracy: 0.8864\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3027 - accuracy: 0.8898\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2927 - accuracy: 0.8927\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2861 - accuracy: 0.8941\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2803 - accuracy: 0.8965\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2751 - accuracy: 0.8977\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2707 - accuracy: 0.9003\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2680 - accuracy: 0.9020\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2613 - accuracy: 0.9022\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2562 - accuracy: 0.9053\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2518 - accuracy: 0.9068\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2494 - accuracy: 0.9073\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2444 - accuracy: 0.9087\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2438 - accuracy: 0.9093\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2366 - accuracy: 0.9122\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2345 - accuracy: 0.9115\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2302 - accuracy: 0.9151\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2295 - accuracy: 0.9155\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2242 - accuracy: 0.9159\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2225 - accuracy: 0.9172\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2205 - accuracy: 0.9174\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2185 - accuracy: 0.9176\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2143 - accuracy: 0.9208\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2113 - accuracy: 0.9212\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2096 - accuracy: 0.9211\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2084 - accuracy: 0.9234\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2046 - accuracy: 0.9228\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2039 - accuracy: 0.9241\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2036 - accuracy: 0.9237\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1990 - accuracy: 0.9260\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1986 - accuracy: 0.9260\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1913 - accuracy: 0.9288\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1932 - accuracy: 0.9285\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1928 - accuracy: 0.9282\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1880 - accuracy: 0.9299\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1842 - accuracy: 0.9318\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1880 - accuracy: 0.9305\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1872 - accuracy: 0.9295\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1845 - accuracy: 0.9311\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1790 - accuracy: 0.9336\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1798 - accuracy: 0.9329\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1783 - accuracy: 0.9333\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1750 - accuracy: 0.9360\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1759 - accuracy: 0.9346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2b30078828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeycZnp49-US",
        "colab_type": "text"
      },
      "source": [
        "###Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK2J81Gry2Zn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "052541f7-cc3e-48d0-a8a7-021882b17df2"
      },
      "source": [
        "\n",
        "test_loss, test_acc = model_LeakyReLU.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.3750 - accuracy: 0.8881\n",
            "\n",
            "Test accuracy: 0.8881000280380249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATBUt9Fx-EZA",
        "colab_type": "text"
      },
      "source": [
        "### 2 Layer Feed forward NN Model with ReLU (Adam)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgKYYwSkoFir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd4666e7-5dff-448a-ad2e-c09d86041805"
      },
      "source": [
        "model_relu = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(128,activation='relu'), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_relu.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_relu.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5004 - accuracy: 0.8247\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3736 - accuracy: 0.8652\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3349 - accuracy: 0.8786\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3110 - accuracy: 0.8866\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2943 - accuracy: 0.8919\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2791 - accuracy: 0.8981\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2670 - accuracy: 0.9018\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2571 - accuracy: 0.9039\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2459 - accuracy: 0.9089\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2382 - accuracy: 0.9113\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2317 - accuracy: 0.9140\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2231 - accuracy: 0.9171\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2165 - accuracy: 0.9188\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2092 - accuracy: 0.9220\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2029 - accuracy: 0.9238\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1970 - accuracy: 0.9264\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1911 - accuracy: 0.9284\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1870 - accuracy: 0.9293\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1818 - accuracy: 0.9325\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1788 - accuracy: 0.9330\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1731 - accuracy: 0.9350\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1709 - accuracy: 0.9356\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1668 - accuracy: 0.9379\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1634 - accuracy: 0.9392\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1591 - accuracy: 0.9409\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1549 - accuracy: 0.9429\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1521 - accuracy: 0.9426\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1461 - accuracy: 0.9444\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1445 - accuracy: 0.9457\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1428 - accuracy: 0.9461\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1389 - accuracy: 0.9479\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1377 - accuracy: 0.9486\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1332 - accuracy: 0.9494\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1308 - accuracy: 0.9513\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1284 - accuracy: 0.9531\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1262 - accuracy: 0.9523\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1240 - accuracy: 0.9540\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1199 - accuracy: 0.9545\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1177 - accuracy: 0.9558\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1158 - accuracy: 0.9560\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1162 - accuracy: 0.9566\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1140 - accuracy: 0.9572\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1110 - accuracy: 0.9583\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1061 - accuracy: 0.9597\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1054 - accuracy: 0.9599\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1055 - accuracy: 0.9606\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1025 - accuracy: 0.9612\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1004 - accuracy: 0.9629\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0979 - accuracy: 0.9636\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0967 - accuracy: 0.9638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ae44e5358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP2Q4HQF-NII",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdpkQfw10Il-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e8b4d014-c772-4e11-a11a-bc25dd2e7908"
      },
      "source": [
        "test_loss, test_acc = model_relu.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.5346 - accuracy: 0.8879\n",
            "\n",
            "Test accuracy: 0.8878999948501587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdeKgMGxAjM_",
        "colab_type": "text"
      },
      "source": [
        "##### PARTB: Discuss how optimizer choice influences performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYiwzMLr-dQG",
        "colab_type": "text"
      },
      "source": [
        "### 2 Layer Feed forward NN Model with Leaky ReLU (RMSprop)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VKGBz8bvQai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d4418be-06d0-47fa-bb54-d72bcbf7e584"
      },
      "source": [
        "model_LeakyRMS = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(128,activation=LeakyReLU()), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_LeakyRMS.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=RMSprop(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_LeakyRMS.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5308 - accuracy: 0.8127\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4116 - accuracy: 0.8534\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3805 - accuracy: 0.8646\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3607 - accuracy: 0.8719\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3471 - accuracy: 0.8764\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3366 - accuracy: 0.8787\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3263 - accuracy: 0.8824\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3189 - accuracy: 0.8856\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3147 - accuracy: 0.8865\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3079 - accuracy: 0.8902\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3030 - accuracy: 0.8925\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2991 - accuracy: 0.8928\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2946 - accuracy: 0.8946\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2907 - accuracy: 0.8948\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2856 - accuracy: 0.8983\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2830 - accuracy: 0.8979\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2811 - accuracy: 0.8995\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2773 - accuracy: 0.9008\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2736 - accuracy: 0.9016\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2721 - accuracy: 0.9034\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2681 - accuracy: 0.9035\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2661 - accuracy: 0.9053\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2642 - accuracy: 0.9051\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2608 - accuracy: 0.9062\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2595 - accuracy: 0.9065\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2574 - accuracy: 0.9075\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2536 - accuracy: 0.9088\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2510 - accuracy: 0.9110\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2503 - accuracy: 0.9115\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2490 - accuracy: 0.9112\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2468 - accuracy: 0.9120\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2457 - accuracy: 0.9129\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2431 - accuracy: 0.9136\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2419 - accuracy: 0.9134\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2402 - accuracy: 0.9150\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2375 - accuracy: 0.9157\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2378 - accuracy: 0.9163\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2352 - accuracy: 0.9168\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2364 - accuracy: 0.9157\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2313 - accuracy: 0.9188\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2322 - accuracy: 0.9174\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2288 - accuracy: 0.9193\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2299 - accuracy: 0.9191\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2276 - accuracy: 0.9202\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2258 - accuracy: 0.9198\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2251 - accuracy: 0.9196\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2229 - accuracy: 0.9205\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2224 - accuracy: 0.9200\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2208 - accuracy: 0.9219\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2192 - accuracy: 0.9218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ae4408278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMqjFqeo_MmA",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrJkSKIN3Pbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3e1f3f42-26f4-4058-8c7d-10d6a077b49d"
      },
      "source": [
        "\n",
        "test_loss, test_acc = model_LeakyRMS.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.4705 - accuracy: 0.8651\n",
            "\n",
            "Test accuracy: 0.8651000261306763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTr9egeP_Vj-",
        "colab_type": "text"
      },
      "source": [
        "### 2 Layer Feed forward NN Model with ReLU (RMSprop)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC4-Pfga3dXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d79696ad-463e-429d-c7d7-2e364ce17faf"
      },
      "source": [
        "model_reluRMS = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(128,activation='relu'), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_reluRMS.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=RMSprop(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_reluRMS.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5092 - accuracy: 0.8185\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3806 - accuracy: 0.8630\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3467 - accuracy: 0.8760\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3306 - accuracy: 0.8834\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3184 - accuracy: 0.8884\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3071 - accuracy: 0.8916\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2992 - accuracy: 0.8963\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2930 - accuracy: 0.8993\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2867 - accuracy: 0.9011\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2819 - accuracy: 0.9036\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2737 - accuracy: 0.9054\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2732 - accuracy: 0.9079\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2675 - accuracy: 0.9112\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2600 - accuracy: 0.9134\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2550 - accuracy: 0.9137\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2547 - accuracy: 0.9158\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2497 - accuracy: 0.9163\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2453 - accuracy: 0.9177\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2413 - accuracy: 0.9182\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2404 - accuracy: 0.9216\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2352 - accuracy: 0.9218\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2324 - accuracy: 0.9232\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2301 - accuracy: 0.9251\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2272 - accuracy: 0.9261\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2228 - accuracy: 0.9278\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2240 - accuracy: 0.9287\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2195 - accuracy: 0.9288\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2182 - accuracy: 0.9294\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2134 - accuracy: 0.9315\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2092 - accuracy: 0.9316\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2067 - accuracy: 0.9340\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2064 - accuracy: 0.9344\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2054 - accuracy: 0.9355\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2036 - accuracy: 0.9356\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1977 - accuracy: 0.9377\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1946 - accuracy: 0.9374\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1925 - accuracy: 0.9393\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1922 - accuracy: 0.9386\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1911 - accuracy: 0.9399\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1906 - accuracy: 0.9407\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1880 - accuracy: 0.9401\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1854 - accuracy: 0.9410\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1832 - accuracy: 0.9429\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1779 - accuracy: 0.9442\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1733 - accuracy: 0.9454\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1769 - accuracy: 0.9440\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1749 - accuracy: 0.9459\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1743 - accuracy: 0.9453\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1714 - accuracy: 0.9462\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1728 - accuracy: 0.9464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8a100eeef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvOxNxXH_dHV",
        "colab_type": "text"
      },
      "source": [
        "###Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE1iJKOE4XSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "363be76b-33ee-450c-a486-7efa8afe05e5"
      },
      "source": [
        "test_loss, test_acc = model_reluRMS.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.7843 - accuracy: 0.8793\n",
            "\n",
            "Test accuracy: 0.8792999982833862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyl_X_25_hoy",
        "colab_type": "text"
      },
      "source": [
        "### 2 Layer Feed forward NN Model with Leaky ReLU (Adagrad)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTeRq9Ha5jCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94ece858-689d-4288-c177-b85da5903d5f"
      },
      "source": [
        "model_LeakyAda = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(128,activation=LeakyReLU()), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_LeakyAda.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adagrad(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_LeakyAda.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.0760 - accuracy: 0.6675\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7110 - accuracy: 0.7685\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6388 - accuracy: 0.7912\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6003 - accuracy: 0.8031\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5752 - accuracy: 0.8101\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5571 - accuracy: 0.8155\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5429 - accuracy: 0.8201\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5314 - accuracy: 0.8233\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5221 - accuracy: 0.8255\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5142 - accuracy: 0.8275\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5073 - accuracy: 0.8304\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5014 - accuracy: 0.8315\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4962 - accuracy: 0.8332\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4916 - accuracy: 0.8346\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4875 - accuracy: 0.8359\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4836 - accuracy: 0.8369\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4802 - accuracy: 0.8383\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4769 - accuracy: 0.8386\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4739 - accuracy: 0.8399\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4712 - accuracy: 0.8410\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4686 - accuracy: 0.8414\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4663 - accuracy: 0.8420\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4640 - accuracy: 0.8428\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4618 - accuracy: 0.8434\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4597 - accuracy: 0.8443\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4578 - accuracy: 0.8447\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4559 - accuracy: 0.8454\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4542 - accuracy: 0.8464\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4526 - accuracy: 0.8465\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4510 - accuracy: 0.8470\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4496 - accuracy: 0.8478\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4480 - accuracy: 0.8479\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4467 - accuracy: 0.8486\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4454 - accuracy: 0.8485\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4441 - accuracy: 0.8493\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4429 - accuracy: 0.8491\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4417 - accuracy: 0.8500\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4406 - accuracy: 0.8504\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4394 - accuracy: 0.8507\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4384 - accuracy: 0.8506\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4374 - accuracy: 0.8508\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4364 - accuracy: 0.8515\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4354 - accuracy: 0.8518\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4345 - accuracy: 0.8519\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4334 - accuracy: 0.8525\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4325 - accuracy: 0.8528\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4317 - accuracy: 0.8527\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4309 - accuracy: 0.8527\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4301 - accuracy: 0.8533\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4292 - accuracy: 0.8539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ae413dfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRDJhqQh_pOu",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fUG7oIX5uUH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5f1c5833-e827-4755-9957-f6a9c893a99e"
      },
      "source": [
        "test_loss, test_acc = model_LeakyAda.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.4647 - accuracy: 0.8364\n",
            "\n",
            "Test accuracy: 0.8363999724388123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neI7u3fE_szU",
        "colab_type": "text"
      },
      "source": [
        "### 2 Layer Feed forward NN Model with  ReLU (Adagrad)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-hcjT_q5wki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7c6b709-6773-4324-c3f0-a4533c318425"
      },
      "source": [
        "model_reluAda = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(128,activation='relu'), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_reluAda.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adagrad(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_reluAda.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.0640 - accuracy: 0.6761\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7159 - accuracy: 0.7710\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6431 - accuracy: 0.7934\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6038 - accuracy: 0.8040\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5779 - accuracy: 0.8106\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5590 - accuracy: 0.8163\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5444 - accuracy: 0.8212\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5325 - accuracy: 0.8238\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5226 - accuracy: 0.8272\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5141 - accuracy: 0.8292\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5067 - accuracy: 0.8314\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5002 - accuracy: 0.8335\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4944 - accuracy: 0.8356\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4892 - accuracy: 0.8372\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4845 - accuracy: 0.8382\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4802 - accuracy: 0.8398\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4762 - accuracy: 0.8413\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4726 - accuracy: 0.8420\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4693 - accuracy: 0.8429\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4661 - accuracy: 0.8439\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4631 - accuracy: 0.8446\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4603 - accuracy: 0.8454\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4578 - accuracy: 0.8455\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4554 - accuracy: 0.8469\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4530 - accuracy: 0.8473\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4508 - accuracy: 0.8480\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4487 - accuracy: 0.8490\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4465 - accuracy: 0.8495\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4448 - accuracy: 0.8499\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4430 - accuracy: 0.8501\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4412 - accuracy: 0.8512\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4395 - accuracy: 0.8512\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4379 - accuracy: 0.8517\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4363 - accuracy: 0.8522\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4349 - accuracy: 0.8529\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4334 - accuracy: 0.8531\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4320 - accuracy: 0.8536\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4307 - accuracy: 0.8543\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4294 - accuracy: 0.8543\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4281 - accuracy: 0.8547\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4269 - accuracy: 0.8552\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4257 - accuracy: 0.8555\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4246 - accuracy: 0.8558\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4234 - accuracy: 0.8567\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4223 - accuracy: 0.8569\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4212 - accuracy: 0.8572\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4202 - accuracy: 0.8575\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4192 - accuracy: 0.8578\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4182 - accuracy: 0.8584\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4173 - accuracy: 0.8581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ae4145048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq8GYLYx_0UI",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3isxIQdV57N3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1fd99ad1-19e3-4d59-a7c8-448498ad4f19"
      },
      "source": [
        "test_loss, test_acc = model_reluAda.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.4505 - accuracy: 0.8440\n",
            "\n",
            "Test accuracy: 0.843999981880188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0NXN66x_3rW",
        "colab_type": "text"
      },
      "source": [
        "### 2 Layer Feed forward NN Model with Leaky ReLU (SGD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz7yi7Rh6elN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "31fde7dd-68e4-40e2-b582-57fca7cd3ad6"
      },
      "source": [
        "model_Leakysgd = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(128,activation=LeakyReLU()), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_Leakysgd.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=SGD(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_Leakysgd.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.3981 - accuracy: 0.5924\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8720 - accuracy: 0.7253\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7474 - accuracy: 0.7602\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6832 - accuracy: 0.7800\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6414 - accuracy: 0.7918\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6113 - accuracy: 0.8006\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5882 - accuracy: 0.8069\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5697 - accuracy: 0.8122\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5546 - accuracy: 0.8151\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5420 - accuracy: 0.8187\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5312 - accuracy: 0.8225\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5218 - accuracy: 0.8243\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5134 - accuracy: 0.8266\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5062 - accuracy: 0.8296\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4996 - accuracy: 0.8311\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4937 - accuracy: 0.8324\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4884 - accuracy: 0.8336\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4835 - accuracy: 0.8349\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4789 - accuracy: 0.8373\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4748 - accuracy: 0.8383\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4711 - accuracy: 0.8389\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4676 - accuracy: 0.8402\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4641 - accuracy: 0.8409\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4609 - accuracy: 0.8423\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4579 - accuracy: 0.8428\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4554 - accuracy: 0.8443\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4526 - accuracy: 0.8450\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4501 - accuracy: 0.8458\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4479 - accuracy: 0.8467\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4454 - accuracy: 0.8473\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4433 - accuracy: 0.8481\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4412 - accuracy: 0.8489\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4393 - accuracy: 0.8491\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4373 - accuracy: 0.8497\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4355 - accuracy: 0.8510\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4337 - accuracy: 0.8511\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4319 - accuracy: 0.8517\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4301 - accuracy: 0.8520\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4286 - accuracy: 0.8525\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4272 - accuracy: 0.8530\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4257 - accuracy: 0.8538\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4239 - accuracy: 0.8539\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4227 - accuracy: 0.8545\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4210 - accuracy: 0.8551\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4197 - accuracy: 0.8554\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4184 - accuracy: 0.8555\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4171 - accuracy: 0.8561\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4159 - accuracy: 0.8566\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4146 - accuracy: 0.8571\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4134 - accuracy: 0.8576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ae40349b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx8Nh3ZR_7cR",
        "colab_type": "text"
      },
      "source": [
        "###Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwiPw2rF6lL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "06d39eb1-cea6-4513-ac08-5f8a449c2443"
      },
      "source": [
        "test_loss, test_acc = model_Leakysgd.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.4508 - accuracy: 0.8437\n",
            "\n",
            "Test accuracy: 0.8436999917030334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJr7c25K__1S",
        "colab_type": "text"
      },
      "source": [
        "### 2 Layer Feed forward NN Model with  ReLU (SGD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTPnpBNo6oM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "125bf1f7-c34d-4723-cf56-1a2b7e9e106f"
      },
      "source": [
        "model_relusgd = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(128,activation='relu'), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_relusgd.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=SGD(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_relusgd.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4178 - accuracy: 0.5919\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.8795 - accuracy: 0.7287\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.7569 - accuracy: 0.7602\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6938 - accuracy: 0.7780\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6514 - accuracy: 0.7906\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6198 - accuracy: 0.7994\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5955 - accuracy: 0.8063\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5757 - accuracy: 0.8110\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5592 - accuracy: 0.8167\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5455 - accuracy: 0.8199\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5336 - accuracy: 0.8235\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5234 - accuracy: 0.8259\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5143 - accuracy: 0.8281\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5064 - accuracy: 0.8299\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4990 - accuracy: 0.8323\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4926 - accuracy: 0.8349\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4868 - accuracy: 0.8361\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4815 - accuracy: 0.8378\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4766 - accuracy: 0.8389\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4722 - accuracy: 0.8400\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4679 - accuracy: 0.8421\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4640 - accuracy: 0.8429\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4602 - accuracy: 0.8440\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4567 - accuracy: 0.8442\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4537 - accuracy: 0.8455\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4505 - accuracy: 0.8462\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4477 - accuracy: 0.8471\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4447 - accuracy: 0.8480\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4422 - accuracy: 0.8491\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4397 - accuracy: 0.8501\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4371 - accuracy: 0.8508\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4349 - accuracy: 0.8510\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4327 - accuracy: 0.8526\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4307 - accuracy: 0.8523\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4284 - accuracy: 0.8536\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4266 - accuracy: 0.8537\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4246 - accuracy: 0.8556\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4227 - accuracy: 0.8554\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4210 - accuracy: 0.8556\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4191 - accuracy: 0.8564\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4176 - accuracy: 0.8573\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4158 - accuracy: 0.8577\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4142 - accuracy: 0.8584\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4125 - accuracy: 0.8589\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4110 - accuracy: 0.8591\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4096 - accuracy: 0.8599\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4082 - accuracy: 0.8603\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4068 - accuracy: 0.8604\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4055 - accuracy: 0.8608\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4042 - accuracy: 0.8617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ad16e4208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKxmBqWhAEqF",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7xCMS856sab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cf53622d-5492-4461-ab02-bdfe943cce77"
      },
      "source": [
        "test_loss, test_acc = model_relusgd.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.4370 - accuracy: 0.8465\n",
            "\n",
            "Test accuracy: 0.8464999794960022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWTVqfTHBxWH",
        "colab_type": "text"
      },
      "source": [
        "##### Inferences:\n",
        "##### By using different optimizers we noticed that we get the highest accuracy with Adam and RMSprop but the loss with least when Adam is used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEBYl3YpAKEd",
        "colab_type": "text"
      },
      "source": [
        "######PART3 : What happens when the number of hidden units chosen is much smaller. Similarly, what happens when the number of hidden units chosen is much higher?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYzl-eIuA2Hk",
        "colab_type": "text"
      },
      "source": [
        "### Choosing a very small hidden unit with ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MFEoYTf2-cji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07600841-0b69-4d06-f4b7-f8b6dd0608ea"
      },
      "source": [
        "model_relu16 = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(16,activation='relu'), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "\n",
        "model_relu16.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_relu16.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6104 - accuracy: 0.7917\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4473 - accuracy: 0.8443\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4192 - accuracy: 0.8541\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4023 - accuracy: 0.8587\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3892 - accuracy: 0.8629\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3808 - accuracy: 0.8652\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3695 - accuracy: 0.8695\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3628 - accuracy: 0.8702\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3576 - accuracy: 0.8729\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3519 - accuracy: 0.8737\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3474 - accuracy: 0.8766\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3415 - accuracy: 0.8770\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3399 - accuracy: 0.8781\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3364 - accuracy: 0.8799\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3329 - accuracy: 0.8796\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3296 - accuracy: 0.8814\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3261 - accuracy: 0.8835\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3256 - accuracy: 0.8834\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3225 - accuracy: 0.8837\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3208 - accuracy: 0.8844\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3176 - accuracy: 0.8858\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3165 - accuracy: 0.8851\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3134 - accuracy: 0.8878\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3131 - accuracy: 0.8874\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3112 - accuracy: 0.8874\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3087 - accuracy: 0.8881\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3080 - accuracy: 0.8893\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3052 - accuracy: 0.8904\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3056 - accuracy: 0.8895\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3037 - accuracy: 0.8899\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3022 - accuracy: 0.8906\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3007 - accuracy: 0.8909\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2997 - accuracy: 0.8913\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2996 - accuracy: 0.8922\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2974 - accuracy: 0.8917\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2954 - accuracy: 0.8933\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2966 - accuracy: 0.8927\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2937 - accuracy: 0.8942\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2930 - accuracy: 0.8942\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2937 - accuracy: 0.8940\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2918 - accuracy: 0.8940\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2908 - accuracy: 0.8936\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2899 - accuracy: 0.8962\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2883 - accuracy: 0.8949\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2878 - accuracy: 0.8955\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2870 - accuracy: 0.8964\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2858 - accuracy: 0.8955\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2851 - accuracy: 0.8970\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2838 - accuracy: 0.8965\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2834 - accuracy: 0.8971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ad05da7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yu0MHIaA_Va",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BIN0ES8h--nT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "67ab1ccc-7762-4573-8398-a8d77452a3cc"
      },
      "source": [
        "test_loss, test_acc = model_relu16.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.4199 - accuracy: 0.8577\n",
            "\n",
            "Test accuracy: 0.857699990272522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2yLh_7sBDAF",
        "colab_type": "text"
      },
      "source": [
        "### Choosing a very high hidden unit with ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raNExsam_ocY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "602e7a1d-8de4-433f-8387-aaf1ce73cf45"
      },
      "source": [
        "model_relu1024 = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(1024,activation='relu'), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "\n",
        "model_relu1024.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_relu1024.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4723 - accuracy: 0.8298\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3554 - accuracy: 0.8702\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3198 - accuracy: 0.8821\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2970 - accuracy: 0.8895\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2770 - accuracy: 0.8974\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2615 - accuracy: 0.9020\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2492 - accuracy: 0.9070\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2382 - accuracy: 0.9104\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2265 - accuracy: 0.9143\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2189 - accuracy: 0.9182\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2099 - accuracy: 0.9205\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2025 - accuracy: 0.9229\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1963 - accuracy: 0.9262\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1874 - accuracy: 0.9299\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1826 - accuracy: 0.9314\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1745 - accuracy: 0.9346\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1716 - accuracy: 0.9353\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1634 - accuracy: 0.9376\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1596 - accuracy: 0.9397\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1558 - accuracy: 0.9410\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1518 - accuracy: 0.9427\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1495 - accuracy: 0.9436\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1420 - accuracy: 0.9463\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1366 - accuracy: 0.9480\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1360 - accuracy: 0.9496\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1306 - accuracy: 0.9507\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1279 - accuracy: 0.9518\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1246 - accuracy: 0.9536\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1237 - accuracy: 0.9525\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1190 - accuracy: 0.9547\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1177 - accuracy: 0.9556\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1150 - accuracy: 0.9565\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1102 - accuracy: 0.9588\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1075 - accuracy: 0.9597\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1067 - accuracy: 0.9600\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1047 - accuracy: 0.9610\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1036 - accuracy: 0.9618\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1007 - accuracy: 0.9627\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0970 - accuracy: 0.9631\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0954 - accuracy: 0.9633\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0936 - accuracy: 0.9646\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0934 - accuracy: 0.9658\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0896 - accuracy: 0.9665\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0876 - accuracy: 0.9665\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0879 - accuracy: 0.9674\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0842 - accuracy: 0.9687\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0865 - accuracy: 0.9681\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0798 - accuracy: 0.9694\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0811 - accuracy: 0.9698\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0794 - accuracy: 0.9707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2acec71208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UmFzVW_wD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f2dcc1ef-4c02-4f0a-92c1-84140ec63597"
      },
      "source": [
        "test_loss, test_acc = model_relu1024.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.6076 - accuracy: 0.8844\n",
            "\n",
            "Test accuracy: 0.8844000101089478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ5f2d5yFCHg",
        "colab_type": "text"
      },
      "source": [
        "### Choosing a very small hidden unit with Leaky ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4fNwGPtBGpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd3c775f-ce41-4eb8-ed06-41ce3318e65c"
      },
      "source": [
        "model_Leaky16 = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(16,activation=LeakyReLU()), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_Leaky16.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_Leaky16.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5791 - accuracy: 0.8031\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4409 - accuracy: 0.8462\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4132 - accuracy: 0.8553\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3967 - accuracy: 0.8602\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3832 - accuracy: 0.8640\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3738 - accuracy: 0.8678\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3658 - accuracy: 0.8691\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3605 - accuracy: 0.8706\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3553 - accuracy: 0.8724\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3507 - accuracy: 0.8749\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3460 - accuracy: 0.8759\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3418 - accuracy: 0.8784\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3387 - accuracy: 0.8788\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3360 - accuracy: 0.8794\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3321 - accuracy: 0.8814\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3306 - accuracy: 0.8806\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3267 - accuracy: 0.8816\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3250 - accuracy: 0.8821\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3229 - accuracy: 0.8833\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3201 - accuracy: 0.8850\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3186 - accuracy: 0.8849\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3173 - accuracy: 0.8847\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8869\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3122 - accuracy: 0.8876\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3104 - accuracy: 0.8869\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3082 - accuracy: 0.8886\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3065 - accuracy: 0.8895\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3067 - accuracy: 0.8889\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3030 - accuracy: 0.8909\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3005 - accuracy: 0.8918\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3022 - accuracy: 0.8894\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3001 - accuracy: 0.8912\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2989 - accuracy: 0.8913\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2980 - accuracy: 0.8916\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2938 - accuracy: 0.8941\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2946 - accuracy: 0.8928\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2932 - accuracy: 0.8947\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2933 - accuracy: 0.8938\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2938 - accuracy: 0.8935\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2911 - accuracy: 0.8942\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2890 - accuracy: 0.8951\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2896 - accuracy: 0.8944\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2887 - accuracy: 0.8949\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2858 - accuracy: 0.8963\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2873 - accuracy: 0.8953\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2853 - accuracy: 0.8946\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2840 - accuracy: 0.8960\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2830 - accuracy: 0.8961\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2819 - accuracy: 0.8965\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2809 - accuracy: 0.8981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ace389cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGESVX7mBZMw",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUKrL5QuI5-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "58cc49e1-19c0-4080-8570-cace168af2bd"
      },
      "source": [
        "test_loss, test_acc = model_Leaky16.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.4119 - accuracy: 0.8594\n",
            "\n",
            "Test accuracy: 0.8593999743461609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5_jzXRaBcU5",
        "colab_type": "text"
      },
      "source": [
        "### Choosing a very high hidden unit with Leaky ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiIJbNrlJPPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3dbcf1d0-1ae5-4335-9440-a147c186b9e2"
      },
      "source": [
        "model_Leaky1024 = Sequential([\n",
        "  Flatten(input_shape=(28, 28, 1)),\n",
        "  Dense(1024,activation=LeakyReLU()), #Hidden layer\n",
        "  Dense(10, activation='softmax') #output layer\n",
        "])\n",
        "model_Leaky1024.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_Leaky1024.fit(\n",
        "    x_train,y_train,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5122 - accuracy: 0.8193\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4142 - accuracy: 0.8513\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3826 - accuracy: 0.8620\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3567 - accuracy: 0.8717\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3477 - accuracy: 0.8744\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3327 - accuracy: 0.8796\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3226 - accuracy: 0.8817\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3155 - accuracy: 0.8852\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3075 - accuracy: 0.8873\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2987 - accuracy: 0.8907\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2893 - accuracy: 0.8933\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2867 - accuracy: 0.8949\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2786 - accuracy: 0.8973\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2751 - accuracy: 0.8996\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2712 - accuracy: 0.9015\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2692 - accuracy: 0.9012\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2623 - accuracy: 0.9048\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2570 - accuracy: 0.9065\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2556 - accuracy: 0.9063\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2499 - accuracy: 0.9090\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2442 - accuracy: 0.9101\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2441 - accuracy: 0.9115\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2406 - accuracy: 0.9120\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2380 - accuracy: 0.9128\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2328 - accuracy: 0.9140\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2303 - accuracy: 0.9161\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2312 - accuracy: 0.9157\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2266 - accuracy: 0.9166\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2249 - accuracy: 0.9179\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2199 - accuracy: 0.9197\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2162 - accuracy: 0.9213\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2147 - accuracy: 0.9208\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2113 - accuracy: 0.9228\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2114 - accuracy: 0.9212\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2101 - accuracy: 0.9242\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2110 - accuracy: 0.9240\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2044 - accuracy: 0.9260\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2058 - accuracy: 0.9243\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1972 - accuracy: 0.9273\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2000 - accuracy: 0.9267\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1941 - accuracy: 0.9296\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1912 - accuracy: 0.9302\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1943 - accuracy: 0.9294\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1888 - accuracy: 0.9304\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1904 - accuracy: 0.9311\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1901 - accuracy: 0.9312\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1843 - accuracy: 0.9321\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1846 - accuracy: 0.9332\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1808 - accuracy: 0.9339\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1833 - accuracy: 0.9341\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2acd2a4710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNFDsrp4BgIT",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIoAGPbEJR5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9e0387b6-fd80-4956-ebe7-45004892d25e"
      },
      "source": [
        "test_loss, test_acc = model_Leaky1024.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.4319 - accuracy: 0.8824\n",
            "\n",
            "Test accuracy: 0.8823999762535095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ34EK8lCO-4",
        "colab_type": "text"
      },
      "source": [
        "##### Inference:\n",
        "##### When we add more neurons then model starts to overfit as accuracy improved but the loss also increased.Also we can see the loss drastically changed compared with the training loss.\n",
        "##### When we reduced the hidden units the model could not fit very well even in 50 epochs in comparision with other models having more neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HtumMHXr0U8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}
